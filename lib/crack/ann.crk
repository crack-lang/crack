# Copyright 2011-2012 Google Inc.
# Copyright 2012 Conrad Steenberg <conrad.steenberg@gmail.com>
# Copyright 2012 Arno Rehn <arno@arnorehn.de>
# 
#   This Source Code Form is subject to the terms of the Mozilla Public
#   License, v. 2.0. If a copy of the MPL was not distributed with this
#   file, You can obtain one at http://mozilla.org/MPL/2.0/.
# 
# Implements some basic annotations that no one should be without.  Included
# are:
# @define name(arg, ...) { contents }
#   defines a macro with the specified arguments (you can then use the macro
#   as @name(args...))
# @interface I { ... }
#   Defines a class as an interface, allowing you to safely do multiple
#   inheritence.
# class A : Object @implements I, J { ... }
#   Makes a class implement the list of interfaces that follows them (this
#   mainly entails doing normal class derivation and implementing the
#   'get<interface>Object()' method.
# class A @impl I, J { ... }
#   Equivalent to "class A : Object I, J { ... }".  Shorthand for the most 
#   common case.

import crack.compiler CrackContext, Location, Token, TOK_COMMA, TOK_LCURLY,
    TOK_LPAREN, TOK_POPERRCTX, TOK_RCURLY, TOK_RPAREN, TOK_STRING;
import crack.cont.array Array;
import crack.cont.treemap TreeMap;
import crack.io cout, FStr, Reader, StandardFormatter, StringFormatter,
    StringWriter, Writer;
import crack.lang die, AssertionError, CString, Exception, Formatter,
    IndexError, InvalidArgumentError;
import crack.runtime free;
import crack.serial SerialReader, SerialWriter;

const NOT_FOUND := 0xFFFFFFFF;

## Serial writer with some additional facilities to simplify macro
## serialization.
class MacroSerializer : SerialWriter {
    TreeMap[String, uint] sourceNames = {};
    uint lastIdx;

    oper init(Writer dst) : SerialWriter(dst) {}

    void writeSrcName(String name) {
        idx := sourceNames.get(name, NOT_FOUND);
        if (idx != NOT_FOUND) {
            write(idx);
        } else {
            # new name, write the index and the
            sourceNames[name] = lastIdx;
            write(lastIdx++);
            write(name);
        }
    }

    void writeLocation(Location loc) {
        writeSrcName(String(loc.getName()));
        write(uint(loc.getLineNumber()));
    }
}

## Serial reader with some additional facilities to simplify macro
## deserialization.
class MacroDeserializer : SerialReader {
    CrackContext ctx;
    Array[String] sourceNames = {4};

    oper init(CrackContext ctx, Reader src) : SerialReader(src), ctx = ctx {}

    String readSrcName() {
        # read the index
        idx := readUInt();
        count := sourceNames.count();
        if (idx > count) {
            throw IndexError(FStr() `Invalid source name index: $idx\n`);
        } else if (idx == count) {
            name := readString();
            sourceNames.append(name);
            return name;
        } else {
            return sourceNames[idx];
        }
    }

    Location readLocation() {
        return ctx.getLocation(readSrcName().buffer, int(readUInt()));
    }
}

class Node;
class NodeIter;

@abstract class NodeList {
    @abstract void pushHead(Node node);
    @abstract void append(Node node);
    @abstract Node popHead();
    @abstract void writeTo(MacroSerializer dst);
    @abstract NodeIter iter();
    @abstract Node getLast();
    @abstract Node getFirst();
    @abstract void expand(CrackContext ctx, Array[NodeList] args);
    @abstract String toString(Array[NodeList] args);
}

@abstract class Node {
    Node next;

    void expand(CrackContext ctx, Array[NodeList] args) {}
    String toString(Array[NodeList] args) {return null;}
    @abstract Location getLocation();
    @abstract void writeTo(MacroSerializer dst);
}

class NodeIter {
    Node node;
    oper init(Node node) : node = node {}
    void next() { node = node.next; }
    bool isTrue() { return node; }
    Node elem() { return node; }
}

Node _readNode(MacroDeserializer src);

## A list of tokens.  These are typically stored in reverse order of the
## actual order of the tokens so that they can be easily "put back" into the
## token stream (after putBack() they will be in the correct order once again)
class NodeListImpl : NodeList {
    Node first, last;

    oper init() {}

    void pushHead(Node node) {
        if (first) {
            node.next = first;
            first = node;
        } else {
            first = last = node;
        }
    }

    void append(Node node) {
        if (last) {
            last.next = node;
            last = node;
        } else {
            first = last = node;
        }
    }

    Node popHead() {
        if (first) {
            if (last is first)
                last = null;
            result := first;
            first = first.next;
            return result;
        } else {
            return null;
        }
    }

    oper init(MacroDeserializer src) {
        # get the number of nodes in the list
        count := src.readUInt();
        while (count--) {
            append(_readNode(src));
            #cout `remaining = $count\n`;
        }
    }

    void writeTo(MacroSerializer dst) {

        # count the nodes and write the count
        node := first;
        uint count;
        while (node) {
            ++count;
            node = node.next;
        }
        #cout `writing count $count\n`;
        dst.write(count);

        # write all of the nodes
        node = first;
        while (node) {
            node.writeTo(dst);
            node = node.next;
        }
    }

    void __write(Formatter fmt, Node node) {
        if (node.next)
            __write(fmt, node.next);
        node.formatTo(fmt);
    }

    void formatTo(Formatter fmt) {
        __write(fmt, first);
    }

    void writeTo(Writer out) {
        StandardFormatter fmt = {out};
        __write(fmt, first);
    }

    NodeIter iter() { return NodeIter(first); }

    ## Node lists are true if they have any contents.
    bool isTrue() { return first; }

    Node getLast() { return last; }
    Node getFirst() { return first; }
    
    void expand(CrackContext context, Array[NodeList] args) {
        for (node :in this)
            node.expand(context, args);
    }
    
    String toString(Array[NodeList] args) {
        StringFormatter sf = {};
        Array[Node] nodeArray = {};
        for (node :in this)
            nodeArray.append(node);
        
        bool first = true;
        for (int i = nodeArray.count() - 1; i >= 0; --i) {
            if (first)
                first = false;
            else
                sf ` `;
            sf `$(nodeArray[i].toString(args))`;
        }
        
        return sf.string();
    }
}

class Tok : Node {
    Token tok;

    oper init(Token tok) : tok = tok {}

    oper init() {}

    void expand(CrackContext ctx, Array[NodeList] args) {
        ctx.putBack(tok);
    }

    String toString(Array[NodeList] args) {
        if (tok.isString())
            return String(tok.getText()).getRepr();
        else
            return String(tok.getText());
    }

    Location getLocation() {
        return tok.getLocation();
    }

    void formatTo(Formatter fmt) {
        if (tok.isString()) {
            fmt.format(' ');
            fmt.format(String(tok.getText()).getRepr());
        } else {
            fmt.format(' ');
            fmt.format(StaticString(tok.getText()));
        }
    }

    void writeTo(Writer out) {
        if (tok.isString()) {
            out.write(' ');
            out.write(String(tok.getText()).getRepr());
        } else {
            out.write(' ');
            out.write(StaticString(tok.getText()));
        }
    }


    void writeTo(MacroSerializer dst) {

        # my node type
        dst.write(0);

        # the token
        dst.write(uint(tok.getType()));
        dst.write(String(tok.getText()));

        dst.writeLocation(tok.getLocation());
    }

    oper init(MacroDeserializer src) {
        type := int(src.readUInt());
        text := src.readString();
        locName := src.readSrcName();
        locLineNum := src.readUInt();

        #cout `read token: $type, $text, $locName, $locLineNum\n`;
        tok = Token(type, text.buffer,
                    src.ctx.getLocation(locName.buffer, int(locLineNum))
                    );
    }
}

class Arg : Node {
    uint argIndex;
    Location loc;

    oper init(Location loc, uint argIndex) :
        loc = loc,
        argIndex = argIndex {
    }

    oper init() {}

    void expand(CrackContext ctx, Array[NodeList] args) {
        for (node :in NodeList.cast(args[argIndex]))
            node.expand(ctx, args);
    }

    String toString(Array[NodeList] args) {
        StringFormatter sf = {};
        argVal := NodeList.cast(args[argIndex]);

        # do the last node so we can add a whitespace separator for every
        # subsequent node.
        if (last := argVal.getLast())
            sf.format(last.toString(args));

        # do the rest of the nodes
        void reverseNodeList(Array[NodeList] args1, StringFormatter out,
                             Node node
                             ) {

            # stop recursing before the last node
            if (node.next) {
                reverseNodeList(args1, out, node.next);
                out ` $(node.toString(args1))`;
            }
        }

        reverseNodeList(args, sf, argVal.getFirst());
        return sf.cString();
    }

    void formatTo(Formatter fmt) { fmt `arg: $argIndex\n`; }
    Location getLocation() { return loc; }

    oper init(MacroDeserializer src) {
        argIndex = src.readUInt();
        loc = src.readLocation();
        #cout `read arg $argIndex\n`;
    }

    void writeTo(MacroSerializer dst) {

        # write my type id
        dst.write(1);

        # write the arg id and location fields
        dst.write(argIndex);
        dst.writeLocation(loc);
    }
}

## Concat nodes concatenate a set of tokens into a single token.  The type and
## location come from the first non-argument token.
class Concat : Node {
    NodeList list;
    int type;
    Location loc;

    oper init(NodeList list, Location loc) :
        loc = loc,
        list = list {
    }

    oper init() {}

    void expand(CrackContext ctx, Array[NodeList] args) {
        StringFormatter concat = {};
        for (item :in list)
            concat.format(item.toString(args));
        concat.format(' \0');

        s := concat.string();
        ctx.inject(@FILE.buffer, @LINE, s.buffer);
    }

    String toString(Array[NodeList] args) {
        die('Concat.toString() called.');
        return null;
    }

    Location getLocation() {
        return loc;
    }

    oper init(MacroDeserializer src) {
        list = NodeListImpl(src);
        type = int(src.readUInt());
        loc = src.readLocation();
    }

    void writeTo(MacroSerializer dst) {
        dst.write(2);

        list.writeTo(dst);
        dst.write(uint(type));
        dst.writeLocation(loc);
    }
}

class Stringify : Node {
    Node node;

    oper init(Node node) : node = node {}

    void expand(CrackContext ctx, Array[NodeList] args) {
        ctx.putBack(Token(TOK_STRING, node.toString(args).buffer,
                          node.getLocation()
                          )
                    );
    }

    String toString(Array[NodeList] args) {
        die('Stringify.toString called.');
        return null;
    }

    Location getLocation() {
        return node.getLocation();
    }

    oper init(MacroDeserializer src) {
        node = _readNode(src);
    }

    void writeTo(MacroSerializer dst) {

        # write my type id.
        dst.write(3);

        node.writeTo(dst);
    }
}

Node _readNode(MacroDeserializer src) {
    type := src.readUInt();
    Node node;
    if (type == 0)
        node = Tok(src);
    else if (type == 1)
        node = Arg(src);
    else if (type == 2)
        node = Concat(src);
    else if (type == 3)
        node = Stringify(src);
    else
        throw AssertionError(FStr() `bogus node $type\n`);

    return node;
}

## Parse macro arguments, returns them as an array of NodeList objects.
Array[NodeList] parseArgs(CrackContext ctx, uint argCount) {
    # extract the arguments from the following tokens
    tok := ctx.getToken();
    if (!tok.isLParen())
        ctx.error(tok, 'left paren expected in macro expansion'.buffer);

    const byte PAREN = 1, BRACK = 2, CURL = 3;

    uint nesting = 1;
    argTokList := NodeListImpl();
    Array[NodeList] args = {argCount};
    Array[byte] brackStack = {4};
    
    # pop everything on the bracket stack up to the matching value.  This 
    # behavior lets us both respect existing balanced delimiters and ignore 
    # unbalanced ones.
    void popTo(Array[byte] brackStack, byte val) {
        for (int i = brackStack.count() - 1; i >= 0; --i) {
            if (brackStack[i] == val) {
                while (brackStack.count() > i)
                    brackStack.delete(brackStack.count() - 1);
            }
        }
    }

    while (true) {
        tok = ctx.getToken();
        if (!brackStack && tok.isComma()) {
            args.append(argTokList);
            argTokList = NodeListImpl();
        } else {
            if (tok.isLParen()) {
                brackStack.append(PAREN);
            } else if (tok.isLBracket()) {
                brackStack.append(BRACK);
            } else if (tok.isLCurly()) {
                brackStack.append(CURL);
            } else if (tok.isRParen()) {
                if (!brackStack)
                    break;
                else
                    popTo(brackStack, PAREN);
            } else if (tok.isRBracket() && brackStack) {
                popTo(brackStack, BRACK);
            } else if (tok.isRCurly() && brackStack) {
                popTo(brackStack, CURL);
            }

            argTokList.pushHead(Tok(tok));
        }
    }

    # if we got a non-empty element left over, add it to the list.
    if (argTokList.getFirst())
        args.append(argTokList);

    # verify that the number of arguments provided was correct
    if (args.count() != argCount) {
        fmt := StringFormatter();
        fmt `Incorrect number of arguments for macro: expected \
$(argCount), got $(args.count())\0`;
        ctx.error(tok, fmt.string().buffer);
    }

    return args;
}

class Macro : NodeListImpl {
    String name;
    uint argCount;

    oper init() {}
    oper init(MacroDeserializer src) : NodeListImpl(src) {
        name = src.readString();
        argCount = src.readUInt();
    }

    void writeTo(MacroSerializer dst) {
        NodeListImpl.writeTo(dst);
        dst.write(name);
        dst.write(argCount);
    }

    void expand(CrackContext ctx) {
        # hold onto the last location
        loc := ctx.getLocation();

        # parse the args.
        args := parseArgs(ctx, argCount);

        # install the "pop error context" token so that our error context only
        # shows up for the expansion of the macro.
        ctx.putBack(Token(TOK_POPERRCTX, '[pop error context]'.buffer,
                          loc
                          )
                    );

        # expand the macro
        Node node = first;
        while (node) {
            node.expand(ctx, args);
            node = node.next;
        }

        # push an error context
        StringFormatter fmt = {};
        fmt `expanded from macro at $(loc.getName()):$(loc.getLineNumber())`;
        ctx.pushErrorContext(fmt.cString().buffer);
    }
}

## Annotation to expand a macro.  This expects a Macro instance as user data.
void expand(CrackContext ctx) {
    mac := Macro.unsafeCast(ctx.getUserData());
    mac.expand(ctx);
}

# macro parser states
ST_NONE := 0;
ST_ESC := 1;   # got a dollar-sign escape
ST_CONCAT := 2;  # got a double-dollar-sign concatenation operator
ST_ISTR := 3; # MUST BE THE HIGHEST VALUE STATE.  Values greater than this
              # indicate levels of nested parens in an i-string.

void define(CrackContext ctx) {
    Macro mac = {};
    TreeMap[String, uint] args = {};
    uint index;
    tok := ctx.getToken();

    if (!tok.isIdent())
        ctx.error(tok, 'Macro name expected after define.'.buffer);
    mac.name = String(tok.getText());

    # parse the '(' that begins the argument list
    tok = ctx.getToken();
    if (!tok.isLParen())
        ctx.error(tok, 'Left paren expected after macro definition'.buffer);

    # read all of the arguments
    while (true) {
        tok = ctx.getToken();
        if (tok.isRParen())
            break;

        if (!tok.isIdent())
            ctx.error(tok, 'identifier expected'.buffer);

        args[String(tok.getText())] = index++;

        tok = ctx.getToken();
        if (tok.isRParen())
            break;
        else if (!tok.isComma())
            ctx.error('comma or end paren expected in macro def'.buffer);
    }
    mac.argCount = index;

    # read the body of the macro
    tok = ctx.getToken();
    if (!tok.isLCurly())
        ctx.error('Expected left bracket'.buffer);

    # read everything until the end bracket
    uint bracketCount = 1;
    int state = ST_NONE;
    NodeListImpl lastConcat = {};  # last concatenation sequence.
    Node node;  # the last node
    while (true) {
        tok = ctx.getToken();
        uint argIndex;

        if (tok.isEnd()) {
            ctx.error(
                'End of file before the end of a macro definition'.buffer
            );
        } else if (state >= ST_ISTR) {
            # keep track of the parens.
            if (tok.isLParen())
                ++state;
            else if (tok.isRParen() && --state == ST_ISTR)
                # we have to tell the tokenizer to continue parsing the
                # i-string.
                ctx.continueIString();
            else if (tok.isIstrBegin())
                ctx.error('Nested interpolation strings may not be used '
                           'in macros.'.buffer
                          );
            else if (tok.isDollar())
                ctx.error('Nested concatenations and stringifications may not '
                           'be used in a macro.'.buffer
                          );
            else if (tok.isIstrEnd())
                state = ST_NONE;
            else if (state == ST_ISTR && tok.isIdent())
                # an identifier takes us immediately back into the i-string
                ctx.continueIString();
        } else if (tok.isIstrBegin()) {
            if (state != ST_NONE)
                ctx.error('An interpolation string may not be used with '
                           'stringification or concatenation.'.buffer
                          );
            state = ST_ISTR;
        # check for brackets, increment or decrement the bracket count.
        } else if (tok.isRCurly()) {
            if (!--bracketCount)
                break;
        } else if (tok.isLCurly()) {
            ++bracketCount;
        } else if (tok.isDollar()) {
            if (state == ST_NONE) {
                state = ST_ESC;
            } else if (state == ST_ESC) {
                if (!node)
                    ctx.error('The macro may not begin with a concatenation '
                               'operator'.buffer
                              );
                else if (node.isa(Tok) &&
                         Tok.cast(node).tok.isIstrEnd()
                         )
                    ctx.error('An interpolation string may not be used with '
                               'stringification or concatenation'.buffer
                              );

                # if we're starting off a new concatenation sequence, add the
                # last node and store the sequence as a new node in the macro.
                if (!lastConcat) {
                    lastConcat.append(node);
                    mac.popHead();
                    mac.pushHead(Concat(lastConcat, tok.getLocation()));
                }

                state = ST_CONCAT;
            } else {
                ctx.error('One two many dollar signs\n'.buffer);
            }
            continue;
        }

        # replace arguments with indices
        if (tok.isIdent() &&
            (argIndex = args.get(String(tok.getText()), NOT_FOUND)) !=
             NOT_FOUND
            )
            node = Arg(tok.getLocation(), argIndex);
        else
            node = Tok(tok);

        # handle special states
        if (state == ST_CONCAT) {

            # concatenation state - add the new node to the concatenation
            # sequence.
            lastConcat.append(node);
            state = ST_NONE;
        } else if (state == ST_ESC) {

            # stringify state - add a stringify node.
            mac.pushHead(Stringify(node));
            state = ST_NONE;
        } else {
            mac.pushHead(node);

            # reset any last concatenation sequence that we've accumulated
            if (lastConcat)
                lastConcat = NodeListImpl();
        }
    }

    # store a new annotation for expanding the macro
    ctx.storeAnnotation(mac.name.buffer, expand, mac);
    mac.oper bind();
}

void export(CrackContext ctx) {

    # get the next token, make sure it's an annotation.
    tok := ctx.getToken();
    if (!tok.isIdent())
        ctx.error(tok, 'Identifier expected'.buffer);
    name := CString(tok.getText(), false);
    ann := ctx.getAnnotation(name.buffer);
    Macro mac;
    if (ann is null) {
        StringFormatter fmt = {};
        fmt `$name is not an annotation.\0`;
        ctx.error(tok, fmt.string().buffer);
    } else {
        mac = Macro.unsafeCast(ann.getUserData());
    }

    # serialize the macro into a string
    flatMac := StringWriter();
    mac.writeTo(MacroSerializer(flatMac));

    StringFormatter code = {};
    f := @FILE; l := @LINE; code `

        void $name(CrackContext ctx) {
            userData :=
                ctx.getUserData();
            Macro mac;
            if (userData is null) {
                StringReader reader = { $(flatMac.string().getRepr()) };
                mac = Macro(MacroDeserializer(ctx, reader));
                ctx.storeAnnotation($(name.getRepr()).buffer, $name,
                                    mac
                                    );
                mac.oper bind();
            } else {
                mac = Macro.unsafeCast(userData);
            }

            mac.expand(ctx);
        }
    \n\0`;
    ctx.inject(f.buffer, l, code.string().buffer);
}

## Call this annotation at the top of your file if you want to export macros.
## It will import everything you need.
void exporter(CrackContext ctx) {
    StringFormatter f = {};
    f `import crack.ann Macro, MacroDeserializer, Node, NodeList, Tok, Arg,
        Stringify, Concat;
       import crack.compiler CrackContext, Token, TOK_STRING;
       import crack.io StringReader;`;
    ctx.inject(@FILE.buffer, @LINE,
               f.cString().buffer);
}

void readIStr(CrackContext ctx, NodeList nodes) {
    depth := 0;

    while (true) {
        tok := ctx.getToken();
        nodes.pushHead(Tok(tok));
        if (tok.isLParen())
            ++depth;
        else if (tok.isRParen() && !--depth)
            ctx.continueIString();
        else if (tok.isIdent() && !depth)
            ctx.continueIString();
        else if (tok.isIstrEnd())
            return;
    }
}

## Reads a sequence of tokens between a specified left and right delimiter 
## which can be nested.  For example, if left and right are TOK_LPAREN and 
## TOK_RPAREN this function would read the following sequence:
##    ( 1 + 2 + (3 + 4) )
##   ^                   ^
NodeList readDelimited(CrackContext ctx, int left, int right) {
    NodeListImpl result = {};

    # get the opening delimiter.
    tok := ctx.getToken();
    if (tok.getType() != left)
        ctx.error(tok, 'Opening delimiter expected.'.buffer);
    result.pushHead(Tok(tok));

    depth := 1;
    while (depth) {
        tok = ctx.getToken();
        if (tok.isEnd())
            ctx.error(tok, 'Premature end of file'.buffer);
        if (tok.getType() == left)
            ++depth;
        else if (tok.getType() == right)
            --depth;
        result.pushHead(Tok(tok));
        if (tok.isIstrBegin())
            readIStr(ctx, result);
    }

    return result;
}

## Read a curly-bracket delimited block.  See readDelimited() for details
NodeList readBlock(CrackContext ctx) {
    return readDelimited(ctx, TOK_LCURLY, TOK_RCURLY);
}

void _parseGenericArgs(CrackContext ctx, NodeList tokens) {
    while (true) {
        tok := ctx.getToken();
        if (!tok.isIdent())
            ctx.error(tok, 'Identifier expected in generic definition'.buffer);
        tokens.append(Tok(tok));

        tok = ctx.getToken();
        tokens.append(Tok(tok));
        if (tok.isRBracket())
            return;
        else if (!tok.isComma())
            ctx.error(tok,
                      'Comma or closing bracket expected in generic definition'.
                       buffer
                      );
    }
}

## Writes a NodeList to an output stream separated by whitespace.
class TokenWriter {
    NodeList tokens;
    oper init(NodeList tokens) : tokens = tokens {}
    void formatTo(Formatter fmt) {
        for (tok :in tokens) {
            fmt.format(tok.toString(null));
            fmt.format(' ');
        }
    }

    void writeTo(Writer out) {
        for (tok :in tokens) {
            out.write(tok.toString(null));
            out.write(' ');
        }
    }
}

void warn(CrackContext ctx) {
    tok := ctx.getToken();
    if (!tok.isString())
        ctx.error(tok, "String expected after @warn annotation".buffer);
    ctx.warn(tok, tok.getText());
}

## A node whose expand() method injects raw text into the token stream.  
## This avoids the need to painstakingly reconstruct the code token by toke.
class _InjectionNode : Node {
    Location __loc;
    String __code;
    
    oper init(Location loc, String code) : __loc = loc, __code = code {}
    
    void expand(CrackContext ctx, Array[NodeList] args) {
        ctx.inject(__loc.getName(), __loc.getLineNumber(), __code.buffer);
    }

    String toString(Array[NodeList] args) { return null; }
    Location getLocation() {
        return __loc;
    }
    
    void writeTo(MacroSerializer dst) {
        throw Exception('Unsupported operation');
    }
}

class Type {
    String name;
    Array[Type] params;
    
    oper init(String name, Array[Type] params) : 
        name = name,
        params = params {
    }
    
    void formatTo(Formatter out) {
        out `$name`;
        if (params) {
            out `$params`;
        }
    }
    
    @static Type parse(CrackContext ctx, NodeList result) {        
        tok := ctx.getToken();
        if (!tok.isIdent())
            ctx.error(tok, 'Identifier expected for type name'.buffer);
        String name = {tok.getText()};
        if (!(result is null))
            result.pushHead(Tok(tok));
        
        Array[Type] params;
        tok = ctx.getToken();
        if (tok.isLBracket()) {
            
            # got a left bracket, parse the type parameters
            params = Array[Type]();
            if (!(result is null))
                result.pushHead(Tok(tok));
            while (true) {
                params.append(Type.parse(ctx, result));
                tok = ctx.getToken();
                if (!(result is null))
                    result.pushHead(Tok(tok));
                if (tok.isRBracket()) {
                    break;
                } else if (!tok.isComma()) {
                    text := 'Comma or right bracket expected in type definition';
                    ctx.error(tok, text.buffer)
                }
            }
                        
        } else {
            ctx.putBack(tok);
        }
        
        return Type(name, params);
    }
}

class Field {
    Type type;
    String name;
    oper init(Type type, String name) : type = type, name = name {}
    
    @static void parse(CrackContext ctx, Array[Field] fields, NodeList result) {
        type := Type.parse(ctx, result);
        
        # parse each of the variables
        while (true) {
            tok := ctx.getToken();
            if (!tok.isIdent()) {
                msg := 'Identifier expected after type in field definition.';
                ctx.error(tok, msg.buffer);
            }
            result.pushHead(Tok(tok));
            
            name := String(tok.getText());
            f := Field(type, name);
            fields.append(f);
            
            # check for a comma or semicolon
            tok = ctx.getToken();
            result.pushHead(Tok(tok));
            if (tok.isSemi())
                return;
            else if (!tok.isComma())
                ctx.error(tok, 
                          I'Comma or semicolon expected after field \
                            definition'.buffer);
        }
    }
}

void struct(CrackContext ctx) {
    tok := ctx.getToken();
    if (!tok.isIdent())
        ctx.error(tok, 'Identifier expexted after @struct annotation'.buffer);
    
    
    className := String(tok.getText());
    
    # start the result token list with "class <tok>"
    NodeListImpl result = {};
    result.pushHead(_InjectionNode(ctx.getLocation(@FILE.buffer, @LINE), 
                                   'class \0'
                                   )
                    );
    result.pushHead(Tok(tok));

    # parse a curly    
    tok = ctx.getToken();
    if (!tok.isLCurly())
        ctx.error(tok, 'Curly brace expected after struct name.'.buffer);
    result.pushHead(Tok(tok));

    Array[Field] fields = {};

    # parse fields
    while (true) {
        
        tok = ctx.getToken();
        if (tok.isRCurly()) {
            break;
        }

        # put it back and parse a field        
        ctx.putBack(tok);
        Field.parse(ctx, fields, result)
    }
    
    # create the constructor.
    
    result.pushHead(_InjectionNode(ctx.getLocation(@FILE.buffer, 
                                                   @LINE),
                                   'oper init('
                                   )
                    );
    
    # arg list
    first := true;
    pfx := '';
    for (field :in fields) {
        result.pushHead(_InjectionNode(ctx.getLocation(@FILE.buffer, 
                                                       @LINE),
                                       FStr() I`$pfx$(field.type) \
                                                $(field.name) \0`
                                       )
                        );
        if (first) {
            pfx = ', ';
            first = false;
        }
    }
    
    result.pushHead(_InjectionNode(ctx.getLocation(@FILE.buffer, 
                                                   @LINE),
                                   ') : '
                                   )
                    );
    
    # initializers
    first = true;
    pfx = '';
    for (field :in fields) {

        result.pushHead(_InjectionNode(ctx.getLocation(@FILE.buffer, 
                                                       @LINE),
                                       FStr() I`$pfx$(field.name) = 
                                                $(field.name) \0`
                                       )
                        );
                            
        if (first) {
            pfx = ', ';
            first = false;
        }
    }

    result.pushHead(_InjectionNode(ctx.getLocation(@FILE.buffer, @LINE), '{}'));

    # push the closing bracket for the class
    result.pushHead(Tok(tok));

    # finally, expand the result    
    for (node :in result)
        node.expand(ctx, null);
}

void assert(CrackContext ctx) {
    expr := readDelimited(ctx, TOK_LPAREN, TOK_RPAREN);
    loc := expr.getFirst().getLocation();
    message := expr.toString(null);
    ctx.inject(@FILE.buffer, @LINE, 
               FStr() I`)) { 
                    import crack.lang AssertionError;
                    import crack.io FStr;
                    throw AssertionError(
                        FStr() \`$(loc.getName()):$(loc.getLineNumber()): \
                            Assertion failed: \
                            \$($(message.getRepr()))\\n\`
                    );
               } \0`.buffer
               );
    expr.expand(ctx, null);
    ctx.inject(@FILE.buffer, @LINE, 'if (!('.buffer)
}

# capitalizes the first letter of 'str'
String _capitalize(String str) {
    if (str[0] >= b'a' && str[0] <= b'z') {
        String copy = String(str);  # create a copy
        copy.buffer[0] = b'A' + str[0] - b'a';
        return copy;
    }

    return str;
}

# quickly create property accessors, inspired by Ruby's attr_accessor and 
# C#'s properties.
void property(CrackContext ctx) {
    readonlyAttr := ctx.getToken();
    ctx.putBack(readonlyAttr);

    if (readonlyAttr.isLParen()) {
        readonlyAttr = null;

        NodeList attrList = readDelimited(ctx, TOK_LPAREN, TOK_RPAREN);

        for (node :in attrList) {
            tok := Tok.cast(node);
            if (tok.tok.isLParen() || tok.tok.isRParen() || tok.tok.isComma()) {
                continue;
            }

            tokText := StaticString(tok.tok.getText());
            if (tokText == 'ro' || tokText == 'readonly') {
                readonlyAttr = tok.tok;
            } else {
                ctx.error(tok.tok, FStr() `Unknown property attribute$(tok)`.buffer);
            }
        }
    } else {
        readonlyAttr = null;
    }

    NodeListImpl typeNodes = {};
    type := Type.parse(ctx, typeNodes);

    nameToken := ctx.getToken();
    if (!nameToken.isIdent()) {
        ctx.error(nameToken, 'Identifier expected after property type'.buffer);
    }

    tok := ctx.getToken();

    NodeList getter = null;
    NodeList setter = null;

    # user defined accessors
    if (tok.isLCurly()) {
        tok = ctx.getToken();

        while (!tok.isRCurly()) {
            if (StaticString(tok.getText()) == "get") {
                getter = readBlock(ctx);
            } else if (StaticString(tok.getText()) == "set") {
                if (!(readonlyAttr is null)) {
                    ctx.error(tok, "readonly properties cannot have setters defined".buffer);
                }
                setter = readBlock(ctx);
            } else if (!tok.isSemi()) {
                ctx.error(tok, FStr() `Unknown identifier$(Tok(tok))`.buffer);
            }
            tok = ctx.getToken();
        }
    } else if (!tok.isSemi()) {
        ctx.error(tok, 'semicolon or opening curly brace expected after property definition'.buffer);
    }

    # setter
    if (readonlyAttr is null) {
        if (setter is null) {
            # default setter
            ctx.inject(@FILE.buffer, @LINE, FStr() `{ _$(nameToken.getText()) = value; } \0`.buffer);
        } else {
            setter.expand(ctx, null);
        }

        ctx.inject(@FILE.buffer, @LINE, ' value) \0'.buffer);

        typeNodes.expand(ctx, null);

        ctx.inject(@FILE.buffer, @LINE, FStr() `void set$(_capitalize(StaticString(nameToken.getText()))) ( \0`.buffer);
    }

    # getter
    if (getter is null) {
        # default getter
        ctx.inject(@FILE.buffer, @LINE, FStr() `{ return _$(nameToken.getText()); } \0`.buffer);
    } else {
        getter.expand(ctx, null);
    }
    ctx.inject(@FILE.buffer, @LINE, FStr() `$(nameToken.getText())() \0`.buffer);
    typeNodes.expand(ctx, null);

    # field
    ctx.inject(@FILE.buffer, @LINE, FStr() `_$(nameToken.getText()); \0`.buffer);
    typeNodes.expand(ctx, null);
}

## An annotation that defines an interface.
void interface(CrackContext ctx) {
    nameTok := ctx.getToken();
    if (!nameTok.isIdent())
        ctx.error(nameTok, 'identifier expected for interface name'.buffer);

    # check for generic arguments
    tok := ctx.getToken();
    NodeListImpl genericArgs = {};
    if (tok.isLBracket()) {
        genericArgs.append(Tok(tok));
        _parseGenericArgs(ctx, genericArgs);
    } else {
        ctx.putBack(tok);
    }

    # for injecting the bind(), release() and get*Object() methods
    StringFormatter f = {};

    # check for base interfaces
    NodeListImpl interfaces = {};
    tok = ctx.getToken();
    if (tok.isColon()) {
        # copied from the @implements annotation below:
        Array[Type] ifaces = {4};
        Token firstTok;
        while (true) {

            tok := ctx.getToken();

            if (firstTok is null)
                firstTok = tok;

            if (tok.isLCurly()) {
                ctx.putBack(tok);
                break;

            # store identifiers in an array so we can generate the get*Object()
            # methods.
            } else if (tok.isIdent()) {
                ctx.putBack(tok);
                ifaces.append(Type.parse(ctx, interfaces));
                continue;
            }
            interfaces.pushHead(Tok(tok));
        }

        f `@abstract Object oper from $(nameTok.getText())();\n`;
        for (iface :in ifaces)
            f I`    Object oper from $(iface) () {
                        return this.oper from $(nameTok.getText())(); }\n`;
        f `}\0`;

    } else {
        ctx.putBack(tok);

        f `
        @abstract Object oper from $(nameTok.getText())();
        @final oper bind() {
            if (!(this is null))
                this.oper from $(nameTok.getText())().oper bind();
        }
        @final oper release() {
            if (!(this is null))
                this.oper from $(nameTok.getText())().oper release();
        }
        @final oper to Object() {
            if (!(this is null))
                return this.oper from $(nameTok.getText())();
            else
                return null;
        }
        @final oper to bool() {
            return !(this is null) &&
                this.oper from $(nameTok.getText())().isTrue();
        }
    }\0`;

    }

    # read the body
    body := readBlock(ctx);

    # remove the closing bracket, store the location for error reporting
    loc := body.popHead().getLocation();

    ctx.inject(loc.getName(), loc.getLineNumber(), f.string().buffer);

    # expand the body and opening bracket
    body.expand(ctx, null);

    # expand the base interface list
    interfaces.expand(ctx, null);

    # inject the class definition
    loc = nameTok.getLocation();
    f = StringFormatter();
    f `@abstract class $(nameTok.getText())$(TokenWriter(genericArgs)) :
        $(interfaces ? String() : "VTableBase")\0`;
    ctx.inject(loc.getName(), loc.getLineNumber(), f.string().buffer);
}

void _implements(CrackContext ctx, bool emitObject) {
    # parse the list of interfaces
    NodeListImpl interfaces = {};
    Array[Type] ifaces = {4};

    Token firstTok;
    while (true) {
        tok := ctx.getToken();

        if (firstTok is null)
            firstTok = tok;

        if (tok.isLCurly()) {
            ctx.putBack(tok);
            break;

        # store identifiers in an array so we can generate the oper from *()
        # methods.
        } else if (tok.isIdent()) {
            ctx.putBack(tok);
            ifaces.append(Type.parse(ctx, interfaces));
            continue;
        }
        interfaces.pushHead(Tok(tok));
    }

    # add a comma to the end of the list (so it will show up at the beginning
    # of the list when we expand it)
    interfaces.append(
        Tok(Token(TOK_COMMA, ",".buffer, firstTok.getLocation()))
    );

    # read the body.
    body := readBlock(ctx);

    # remove the closing bracket, store the location for error reporting
    loc := body.popHead().getLocation();

    # inject the get*Object() implementation
    StringFormatter f = {};
    for (iface :in ifaces) 
        f `    Object oper from $iface() { return this; }\n`;
    f `}\0`;
    ctx.inject(loc.getName(), loc.getLineNumber(), f.string().buffer);

    # inject the body
    body.expand(ctx, null);

    # inject the interfaces
    for (node :in interfaces)
        node.expand(ctx, null);
    
    # emit ": Object" for @impl
    if (emitObject) {
        loc = firstTok.getLocation();
        ctx.inject(loc.getName(), loc.getLineNumber(), ': Object'.buffer);
    }
}

## An annotation to be used before the list of interfaces that a class
## implements, e.g.
void implements(CrackContext ctx) {
    _implements(ctx, false);
}

## Shorthand so we can say "class A @impl IFace" instead of 
## "class A : Object @implements IFace"
void impl(CrackContext ctx) {
    _implements(ctx, true);
}
