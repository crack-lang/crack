// A test suite for crack
// Copyright 2010-2012 Google Inc.
// Copyright 2010-2011 Shannon Weyrick <weyrick@mozek.us>
// Copyright 2011 Arno Rehn <arno@arnorehn.de>
// Copyright 2011-2012 Conrad Steenberg <conrad.steenberg@gmail.com>
// 
//   This Source Code Form is subject to the terms of the Mozilla Public
//   License, v. 2.0. If a copy of the MPL was not distributed with this
//   file, You can obtain one at http://mozilla.org/MPL/2.0/.
// 

import crack.ascii radix;
import crack.lang Formatter;
import crack.net Poller;
import crack.fs makePath, Path;
import crack.io cout, cerr, StandardFormatter, Writer, StringWriter, StringFormatter, FStr;
import crack.sys argv, exit;
import crack.exp.dir Directory;
import crack.exp.file File, FileInfo;
import crack.regex Regex, Match;
import crack.process Process;
import crack.cmdline CmdOptions, Option, CMD_STR, CMD_INT, CMD_BOOL;
import crack.cont.hashmap HashMap;
import crack.cont.array Array;
import crack.cont.priorityqueue PriorityQueue;
import crack.strutil StringArray, split;

import stats testSuiteStats;
import testdata Template, TestData, VarMap;
import builders BuilderTestHarness, CrackBuilderDef, builderDefList, Result;
import config config, T_INIT, T_RUNNING, T_FINISHED;
@import crack.ann implements;
import crack.functor Functor2;

# demand-load macros from config.
VarMap _macros;
VarMap getMacros() {
    if (!_macros) {
        _macros = VarMap();
        _macros['SOURCEDIR'] = config.sourceDir.getFullName() + '/';
        _macros['BUILDDIR'] = config.buildDir.getFullName() + '/';
        _macros['OUTDIR'] = config.outDir.getFullName() + '/';
        _macros['SCRIPTNAME'] = 'script name not defined!';
        _macros['CRACKBIN'] = config.crackBin;
        
        # these get filled in from the dir config
        _macros['OPTS'] = '';
        _macros['ARGS'] = ''
    }
    
    return _macros;
}

// represent single test template
// parse template, store data fields, write script
// maintain state while running available builders so we
//     don't hang on any one builder
// maintain final concatenated output of all builders run on this test
// a test is finished when all of the configured builders have run
class Test {

    TestData _data = {};
    String scriptName;
    StringWriter _output = {};
    StringWriter _vOutput = {};

    int _status = T_INIT;
    Array[BuilderTestHarness] _harness = {};
    int _activeHarness = 0;

    bool pass = false;

    String _isSkipped;

    // for the benefit of the priority queue, by default we give higher priority to tests
    // based on comparing the file name. thus, 0_foo is higher priority than 1_foo
    // note this is not strictly the same as sorting them by name, because of the
    // properties of the heap structure.
    int cmp(Object other) {
        if (o := Test.cast(other, null)) {
            return -(_data.fInfo.getName().cmp(o._data.fInfo.getName()));
        } else {
            return Object.cmp(other);
        }
    }

    // ensure test has required sections and that they contain valid data
    // also check to see if we're skipping this test for some reason
    void checkTemplate() {
        if (!_data.sections.hasKey("FILE")) {
            _isSkipped = "the template was missing a FILE section";
        }
        if (!_data.sections.hasKey("EXPECT") && !_data.sections.hasKey("REXPECT")) {
            _isSkipped = "the template was missing an EXPECT or REXPECT section";
        }
        if (_data.sections.hasKey("TEST"))
            _data.desc = _data.sections["TEST"].rtrim();
    }

    void writeScript() {
        
        _data.scriptName = scriptName;
        out := File(_data.scriptName,"w");

        text := _data.sections["FILE"];

        out.write(text);
        
    }

    void run(Poller poller) {
        
        if (_isSkipped) {
            cout `[$(_data.fInfo)]: SKIPPED: $_isSkipped\n`;
            _status = T_FINISHED;
            return;
        }
        
        writeScript();

        _status = T_RUNNING;

        // start initial harness
        _activeHarness = 0;
        _harness[_activeHarness].run(poller);

    }

    void checkResult(Result r) {
        if (!r)
            return;
        if (!r.pass &&
            (config.showDiff || config.stopOnFail) &&
            r.expected.size) {
            _output.write(FStr() `\n---- Diff ----\nExpected: [$(r.expected)]`);
            _output.write(FStr() `\nActual: [$(r.actual)]\n--------------\n`);
        }
    }
/*

    XXX merely defining this function causes a strange overload bug to appear

    bool _allBuildersPass() {
        for (b :in _harness) {
            if ((b.crackResult && !b.crackResult.pass) ||
                (b.binaryResult && !b.binaryResult.pass))
                return false;
        }
        return true;
    }
*/

    int tick(Poller poller) {

        if (_status == T_FINISHED)
            return _status;

        // poll the builder process
        // if finished, get/show output, increment activeBuilder
        if (_harness[_activeHarness].tick(poller) == T_FINISHED) {

            if (config.verbose)
                _vOutput.write(_harness[_activeHarness].vOutput.string());
            _output.write(_harness[_activeHarness].output.string());

            checkResult(_harness[_activeHarness].crackResult);
            checkResult(_harness[_activeHarness].binaryResult);

            _activeHarness++;
            if (_activeHarness < _harness.count()) {
                _harness[_activeHarness].run(poller);
            }
            else {
                _status = T_FINISHED;
                cout `[$(_data.fInfo)]: $(_data.desc)\n`;
                cout `$(_vOutput.string())`;
                cout `$(_output.string())\n`;

                pass = true;
                for (b :in _harness) {
                    if ((b.crackResult && !b.crackResult.pass) ||
                        (b.binaryResult && !b.binaryResult.pass))
                        pass = false;
                }

                if (!pass) {
                    testSuiteStats.failList.append(_data.fInfo.getName());
                    if (config.stopOnFail) {
                        // XXX close procs nicely?
                        exit(0);
                    }
                }

            }

        }

        return _status;

    }

    oper init(Path testFile, Template dc) {
        _data.fInfo = testFile;
        stem := _data.fInfo.getName().slice(0, -5);  // remove '.crkt'
        scriptName = (config.outDir/(stem + ".crk")).getFullName();
        getMacros()['SCRIPTNAME'] = scriptName;
        getMacros()['UNIQ'] = radix(scriptName.makeHashVal(), 16);
        _data.sections = dc.merge(Template.load(testFile));
        _data.sections.expandAll(getMacros());
        
        # make sure we've got everything we need
        checkTemplate();

        // setup test harnesses for this test, based on the builders
        // that have been selected
        for (b :in config.builders) {
            _harness.append((CrackBuilderDef.cast(b)).newTestHarness(_data));
        }
    }

    void _dump(Writer out) {
        for (t :in _data.sections)
            StandardFormatter(out) `[$(t.key)]:\n$(t.val)`;
    }

    void formatTo(Formatter fmt) {
        fmt `[$(_data.fInfo)]: $(_data.desc)\n`;
    }

}

// handle command line
// find all tests
// handle queue of active tests
// decide which builders to run
class TestSuite {

    bool _singleTest = false;
    PriorityQueue[Test] _testList = {};
    CmdOptions _options = {};
    Poller __poller = {};
    
    void usage() {
        _options.printUsage(FStr() `Usage: $(argv[0]) -c <crack binary> [options]\n`);
        exit(1);
    }
    
    Template getDirConfig(Path dir) {

        // directory based config
        dcFile := dir/"options";
        if (dcFile.exists()) {
            sec := Template.load(dcFile);
            macros := getMacros();
            if (sec.hasKey("OPTS"))
                macros['OPTS'] = macros.expand(sec["OPTS"].rtrim());
            if (sec.hasKey('ARGS'))
                macros['ARGS'] = macros.expand(sec['ARGS'].rtrim());
            return sec;
        } else {
            # return an empty template
            return Template();
        }
    }

    void scanForTests(Path dir) {
    
        cout `importing tests from $dir ... `;
        dc := getDirConfig(dir);

        // gather test files
        cnt := 0;
        for (curFile :in dir.children()) {
            if (!curFile.isDir() && curFile.getName().substr(-5) == ".crkt") {
                cnt++;
                _testList.push(Test(curFile, dc));
            }
        }

        cout `found $cnt\n`;
        
        // recurse through children
        for (child :in dir.children()) {
            if (child.isDir())
                scanForTests(child);
        }

    }

    void __processTestOutput() {
        // wait for the next events and process them all.
        if (__poller)
            __poller.waitAndProcess(null);
    }

    void runTests() {

        if (_testList.count() < config.jobs)
            config.jobs = _testList.count();

        if (_testList.count() == 1)
            cout `running single test`;
        else
            cout `running $(_testList.count()) total tests in $(config.jobs) concurrent jobs`;
        cout ` with output in $(config.outDir)...\n`;

        Array[Test] active = {};
        Test cur;
        while (_testList.count() || active.count()) {

            // process pending events
            __processTestOutput();

            // check active for finished tests, remove
            Array[Test] newActive = {};
            for (test :in active)
                if (test.tick(__poller) != T_FINISHED)
                    newActive.append(test);
            active = newActive;

            // add to active if active.count <= max
            while (_testList.count() &&
                   active.count() < config.jobs) {
                cur = _testList.pop();
                active.append(cur);
                cur.run(__poller);
            }

        }

    }

    void checkBinary() {
        // check binary
        cfi := FileInfo(config.crackBin);
        if (!cfi.exists()) {
            cout `crack binary [$(config.crackBin)] not found\n`;
            exit(1);
        }

        p := Process(config.crackBin+" --version");
        p.wait();
        String out = {};
        if (!p.failed())
            out = p.getStdOut();
        if (p.failed() || p.getReturnCode() != 0) {
            cout `crack binary [$(config.crackBin)] failed to run, or unexpected result\n`;
            exit(1);
        }
        else if (out.size < 5 || out.slice(0,5) != "crack") {
            cout `crack binary [$(config.crackBin)] invalid version response: $(out.slice(0,5))\n`;
            exit(1);
        }
        else {
            cout `using binary: $out\n`;
        }
    }

    oper init() {
        
        StringArray bDefStrings = {};
        for (i :in builderDefList) {
            bDefStrings.append(i.key);
        }
        String availBuilders = bDefStrings.join(',');

        _options.add("crackbin", "c", "Crack binary to test", "", CMD_STR);
        _options.add("help", "h", "Show usage", "f", CMD_BOOL);
        _options.add("verbose", "v", "Show verbose output", "f", CMD_BOOL);
        _options.add("jobs", "j", "Number of concurrent jobs", "4", CMD_INT);
        _options.add("testdir", "d", "Directory to search recursively for tests", "./tests", CMD_STR);
        _options.add("testfile", "f", "Single test template to execute", "", CMD_STR);
        _options.add("outdir", "o", "Directory to create output files", "./output", CMD_STR);
        _options.add("libpath", "l", "Add path to crack library path during test. May be colon seperated list.", "", CMD_STR);
        _options.add("builders", "b", "Builders to test, comma delimited list ["+availBuilders+"]","jit", CMD_STR);
        _options.add("sourcedir", "s", "The crack source root directory, which will be used in variable substitution", "", CMD_STR);
        _options.add("builddir", "t", "The crack build directory, which will be used in variable substitution", "", CMD_STR);
        _options.add("diff", "", "Show a diff of expected vs actual output if a test fails","f", CMD_BOOL);
        _options.add("stop-on-fail", "", "Stop on first test failure and display diff","f", CMD_BOOL);
        _options.parse(argv);
                
        if (_options.getBool("help"))
            usage();

        // binary - required
        config.crackBin = _options.getString("crackbin");
        if (config.crackBin == "") {
            cerr `you must explicitly specify the crack binary via the -c option\n\n`;
            usage();
        }
        
        config.rootDir = makePath(_options.getString("testdir"));
        config.outDir = makePath(_options.getString("outdir"));
        config.sourceDir = makePath(_options.getString("sourcedir"));
        config.buildDir = makePath(_options.getString("builddir"));

        config.libPath = _options.getString("libpath");
        config.verbose = _options.getBool("verbose");
        config.jobs = _options.getInt("jobs");
        if (config.jobs <= 0)
            config.jobs = 1;
        config.showDiff = _options.getBool("diff");
        config.stopOnFail = _options.getBool("stop-on-fail");

        if (config.stopOnFail)
            config.showDiff = true;

        // verify, initialize builder defs
        builders := _options.getString("builders");
        clb := split(builders, ",");
        for (b :in clb) {
            if (bDefStrings.contains(b)) {
                config.builders.append(builderDefList[b]);
            }
            else {
                cout `invalid builder specified: $b`;
                exit(1);
            }
        }

        testFile := _options.getString("testfile");
        if (testFile != "") {
            // if specific file, clear directory
            config.rootDir = null;
            _singleTest = true;
            fi := makePath(testFile);
            if (!fi.exists()) {
                cerr `$testFile does not exist\n`;
                exit(1);
            }
            test := Test(fi, getDirConfig(fi.parent()));
            _testList.push(test);
            config.showDiff = true;
            config.jobs = 1;
        }

        // banner
        //cout `screen\n`;

        // in the future, do a version check to make sure we have a good crack binary
        //checkBinary();
        
    }
    
    void showStats() {

        cout `total runtime: $(testSuiteStats.getTotalTime()) secs\n`;

        cnt := testSuiteStats.failList.count();
        if (cnt == 0) {
            cout `all tests passed\n`;
            return;
        }

        cout `-----------------------\n$cnt failing tests:\n`;
        for (f :in testSuiteStats.failList) {
            cout `$f\n`;
        }
        cout `-----------------------\n`;

    }

    void run() {
        
        if (config.rootDir)
            scanForTests(config.rootDir);

        if (!config.outDir.isDir()) {
            cerr `invalid output directory: $(config.outDir)\n`;
            return;
        }

        testSuiteStats.startStopwatch();
        runTests();
        testSuiteStats.stopStopwatch();

        if (!_singleTest)
            showStats();
        
    }

}

suite := TestSuite();
suite.run();

if (testSuiteStats.failList)
    exit(2);  # an exit code of 2 indicates that we failed due to a test 
              # failure
