// A test suite for crack
// Copyright 2010-2011 Shannon Weyrick <weyrick@mozek.us>

import crack.lang Formatter;
import crack.net Poller;
import crack.io cout, cerr, StandardFormatter, Writer, StringWriter, StringFormatter, FStr;
import crack.sys argv, exit;
import crack.exp.dir Directory;
import crack.exp.file File, FileInfo;
import crack.regex Regex, Match;
import crack.process Process;
import crack.cmdline CmdOptions, Option, CMD_STR, CMD_INT, CMD_BOOL;
import crack.cont.hashmap HashMap;
import crack.cont.array Array;
import crack.cont.priorityqueue PriorityQueue;
import crack.strutil StringArray, split;

import stats testSuiteStats;
import testdata TestData, DirConfig;
import builders BuilderTestHarness, CrackBuilderDef, builderDefList, Result;
import config config, T_INIT, T_RUNNING, T_FINISHED;
@import crack.ann implements;
import crack.functor Functor2;

# variable pattern
Regex varPat = {r'%([A-Z]+)%'};

class VarMap : HashMap[String, String] 
               @implements Functor2[void, Match, Writer] {
    void oper call(Match match, Writer writer) {
        var := match.group(1);
        writer.write(get(var, ''));
    }
}

# demand-load macros from config.
VarMap _macros;
VarMap getMacros() {
    if (!_macros) {
        _macros = VarMap();
        _macros['SOURCEDIR'] = config.sourceDir.nameWithTrailing();
        _macros['BUILDDIR'] = config.buildDir.nameWithTrailing();
        _macros['OUTDIR'] = config.outDir.nameWithTrailing();
        _macros['SCRIPTNAME'] = 'script name not defined!';
        _macros['CRACKBIN'] = config.crackBin;
        
        # this gets filled in from the dir config
        _macros['OPTS'] = '';
    }
    
    return _macros;
}

class Template {

     @static
     HashMap[String, String] load(String fileName) {

        HashMap[String, String] sections = {};

        f := File(fileName, "r");
        if (!f.isValid()) {
            cout `file: $(fileName) could not be opened!\n`;
            return null;
        }

        // parse out sections
        String lineBuf, curSection;
        StringWriter dataBuf = {};
        headerPat := Regex('^%%(\\w+)%%$');
        while (lineBuf = f.nextLine()) {
            // look for section change
            m := headerPat.search(lineBuf);
            if (m) {
                if (curSection)
                    sections[curSection] = 
                        varPat.subst(dataBuf.string(), getMacros(), -1);
                curSection = m.group(1);
                //cerr `debug: switching to group $curSection\n`;
                dataBuf = StringWriter();
            }
            else {
                // add line to current section
                dataBuf.write(lineBuf);
            }
        }
        if (curSection)
            sections[curSection] =
                varPat.subst(dataBuf.string(), getMacros(), -1);

        return sections;

    }

}

// represent single test template
// parse template, store data fields, write script
// maintain state while running available builders so we
//     don't hang on any one builder
// maintain final concatenated output of all builders run on this test
// a test is finished when all of the configured builders have run
class Test {

    TestData _data = {};
    String scriptName;
    StringWriter _output = {};
    StringWriter _vOutput = {};

    int _status = T_INIT;
    Array[BuilderTestHarness] _harness = {};
    int _activeHarness = 0;

    bool pass = false;

    String _isSkipped;

    // for the benefit of the priority queue, by default we give higher priority to tests
    // based on comparing the file name. thus, 0_foo is higher priority than 1_foo
    // note this is not strictly the same as sorting them by name, because of the
    // properties of the heap structure.
    int cmp(Object other) {
        if (other.isa(Test)) {
            return -(_data.fInfo.name.cmp(Test.unsafeCast(other)._data.fInfo.name));
        }
        else {
            return 0;
        }
    }

    // ensure test has required sections and that they contain valid data
    // also check to see if we're skipping this test for some reason
    void checkTemplate() {
        if (!_data.sections.hasKey("FILE")) {
            _isSkipped = "the template was missing a FILE section";
        }
        if (!_data.sections.hasKey("EXPECT") && !_data.sections.hasKey("REXPECT")) {
            _isSkipped = "the template was missing an EXPECT or REXPECT section";
        }
        if (_data.sections.hasKey("TEST"))
            _data.desc = _data.sections["TEST"].rtrim();
    }

    void writeScript() {
        
        _data.scriptName = scriptName;
        out := File(_data.scriptName,"w");

        text := _data.sections["FILE"];

        out.write(text);
        
    }

    void run(Poller poller) {
        
        if (_isSkipped) {
            cout `[$(_data.fInfo)]: SKIPPED: $_isSkipped\n`;
            _status = T_FINISHED;
            return;
        }
        
        writeScript();

        _status = T_RUNNING;

        // start initial harness
        _activeHarness = 0;
        _harness[_activeHarness].run(poller);

    }

    void checkResult(Result r) {
        if (!r)
            return;
        if (!r.pass &&
            (config.showDiff || config.stopOnFail) &&
            r.expected.size) {
            _output.write(FStr() `\n---- Diff ----\nExpected: [$(r.expected)]`);
            _output.write(FStr() `\nActual: [$(r.actual)]\n--------------\n`);
        }
    }
/*

    XXX merely defining this function causes a strange overload bug to appear

    bool _allBuildersPass() {
        for (b :in _harness) {
            if ((b.crackResult && !b.crackResult.pass) ||
                (b.binaryResult && !b.binaryResult.pass))
                return false;
        }
        return true;
    }
*/

    int tick(Poller poller) {

        if (_status == T_FINISHED)
            return _status;

        // poll the builder process
        // if finished, get/show output, increment activeBuilder
        if (_harness[_activeHarness].tick(poller) == T_FINISHED) {

            if (config.verbose)
                _vOutput.write(_harness[_activeHarness].vOutput.string());
            _output.write(_harness[_activeHarness].output.string());

            checkResult(_harness[_activeHarness].crackResult);
            checkResult(_harness[_activeHarness].binaryResult);

            _activeHarness++;
            if (_activeHarness < _harness.count()) {
                _harness[_activeHarness].run(poller);
            }
            else {
                _status = T_FINISHED;
                cout `[$(_data.fInfo)]: $(_data.desc)\n`;
                cout `$(_vOutput.string())`;
                cout `$(_output.string())\n`;

                pass = true;
                for (b :in _harness) {
                    if ((b.crackResult && !b.crackResult.pass) ||
                        (b.binaryResult && !b.binaryResult.pass))
                        pass = false;
                }

                if (!pass) {
                    testSuiteStats.failList.append(_data.fInfo.name);
                    if (config.stopOnFail) {
                        // XXX close procs nicely?
                        exit(0);
                    }
                }

            }

        }

        return _status;

    }

    oper init(FileInfo info, DirConfig dc) {
        _data.fInfo = info;
        _data.dirConfig = dc;
        scriptName = config.outDir.nameWithTrailing() +
                     _data.fInfo.basename(true) + ".crk";
        getMacros()['SCRIPTNAME'] = scriptName;
        _data.sections = Template.load(info.name);
        if (_data.sections is null) {
            _isSkipped = "unabled to open file";
            _status = T_FINISHED;
            return;
        }
        checkTemplate();
        // setup test harnesses for this test, based on the builders
        // that have been selected
        for (b :in config.builders) {
            _harness.append((CrackBuilderDef.cast(b)).newTestHarness(_data));
        }
    }

    void _dump(Writer out) {
        for (t :in _data.sections)
            StandardFormatter(out) `[$(t.key)]:\n$(t.val)`;
    }

    void formatTo(Formatter fmt) {
        fmt `[$(_data.fInfo)]: $(_data.desc)\n`;
    }

}

// handle command line
// find all tests
// handle queue of active tests
// decide which builders to run
class TestSuite {

    bool _singleTest = false;
    PriorityQueue[Test] _testList = {};
    CmdOptions _options = {};
    Poller __poller = {};
    
    void usage() {
        _options.printUsage(FStr() `Usage: $(argv[0]) -c <crack binary> [options]\n`);
        exit(1);
    }
    
    DirConfig getDirConfig(Directory dir) {

        // directory based config
        DirConfig dc;
        dcFile := FileInfo(dir.nameWithTrailing() + "options");
        if (dcFile.exists()) {
            sec := Template.load(dcFile.name);
            if (sec.hasKey("OPTS")) {
                dc = DirConfig();
                getMacros()['OPTS'] = dc.options = sec["OPTS"].rtrim();
            }
        }

        return dc;

    }

    void scanForTests(Directory dir) {
    
        if (!dir.isValid()) {
            cerr `skipping invalid directory: $dir\n`;
            return;
        }
        
        cout `importing tests from $dir ... `;

        dc := getDirConfig(dir);

        // gather test files
        cnt := 0;
        for (curFile :in dir.files()) {
            if (curFile.matches("*.crkt")) {
                cnt++;
                _testList.push(Test(curFile, dc));
            }
        }

        cout `found $cnt\n`;
        
        // recurse to directories
        for (nextDir :in dir.dirs()) {
            scanForTests(nextDir);
        }

    }

    void __processTestOutput() {
        // wait for the next events and process them all.
        if (__poller)
            __poller.waitAndProcess(null);
    }

    void runTests() {

        if (_testList.count() < config.jobs)
            config.jobs = _testList.count();

        if (_testList.count() == 1)
            cout `running single test`;
        else
            cout `running $(_testList.count()) total tests in $(config.jobs) concurrent jobs`;
        cout ` with output in $(config.outDir)...\n`;

        Array[Test] active = {};
        Test cur;
        while (_testList.count() || active.count()) {

            // process pending events
            __processTestOutput();

            // check active for finished tests, remove
            Array[Test] newActive = {};
            for (test :in active)
                if (test.tick(__poller) != T_FINISHED)
                    newActive.append(test);
            active = newActive;

            // add to active if active.count <= max
            while (_testList.count() &&
                   active.count() < config.jobs) {
                cur = _testList.pop();
                active.append(cur);
                cur.run(__poller);
            }

        }

    }

    void checkBinary() {
        // check binary
        cfi := FileInfo(config.crackBin);
        if (!cfi.exists()) {
            cout `crack binary [$(config.crackBin)] not found\n`;
            exit(1);
        }

        p := Process(config.crackBin+" --version");
        p.wait();
        String out = {};
        if (!p.failed())
            out = p.getStdOut();
        if (p.failed() || p.getReturnCode() != 0) {
            cout `crack binary [$(config.crackBin)] failed to run, or unexpected result\n`;
            exit(1);
        }
        else if (out.size < 5 || out.slice(0,5) != "crack") {
            cout `crack binary [$(config.crackBin)] invalid version response: $(out.slice(0,5))\n`;
            exit(1);
        }
        else {
            cout `using binary: $out\n`;
        }
    }

    oper init() {
        
        StringArray bDefStrings = {};
        for (i :in builderDefList) {
            bDefStrings.append(i.key);
        }
        String availBuilders = bDefStrings.join(',');

        _options.add("crackbin", "c", "Crack binary to test", "", CMD_STR);
        _options.add("help", "h", "Show usage", "f", CMD_BOOL);
        _options.add("verbose", "v", "Show verbose output", "f", CMD_BOOL);
        _options.add("jobs", "j", "Number of concurrent jobs", "4", CMD_INT);
        _options.add("testdir", "d", "Directory to search recursively for tests", "./tests", CMD_STR);
        _options.add("testfile", "f", "Single test template to execute", "", CMD_STR);
        _options.add("outdir", "o", "Directory to create output files", "./output", CMD_STR);
        _options.add("libpath", "l", "Add path to crack library path during test. May be colon seperated list.", "", CMD_STR);
        _options.add("builders", "b", "Builders to test, comma delimited list ["+availBuilders+"]","jit", CMD_STR);
        _options.add("sourcedir", "s", "The crack source root directory, which will be used in variable substitution", "", CMD_STR);
        _options.add("builddir", "t", "The crack build directory, which will be used in variable substitution", "", CMD_STR);
        _options.add("diff", "", "Show a diff of expected vs actual output if a test fails","f", CMD_BOOL);
        _options.add("stop-on-fail", "", "Stop on first test failure and display diff","f", CMD_BOOL);
        _options.parse(argv);
                
        if (_options.getBool("help"))
            usage();

        // binary - required
        config.crackBin = _options.getString("crackbin");
        if (config.crackBin == "") {
            cerr `you must explicitly specify the crack binary via the -c option\n\n`;
            usage();
        }
        
        config.rootDir = Directory(_options.getString("testdir"), false);
        config.outDir = Directory(_options.getString("outdir"), false);
        config.sourceDir = Directory(_options.getString("sourcedir"), false);
        config.buildDir = Directory(_options.getString("builddir"), false);

        config.libPath = _options.getString("libpath");
        config.verbose = _options.getBool("verbose");
        config.jobs = _options.getInt("jobs");
        if (config.jobs <= 0)
            config.jobs = 1;
        config.showDiff = _options.getBool("diff");
        config.stopOnFail = _options.getBool("stop-on-fail");

        if (config.stopOnFail)
            config.showDiff = true;

        // verify, initialize builder defs
        builders := _options.getString("builders");
        clb := split(builders, ",");
        for (b :in clb) {
            if (bDefStrings.contains(b)) {
                config.builders.append(builderDefList[b]);
            }
            else {
                cout `invalid builder specified: $b`;
                exit(1);
            }
        }

        testFile := _options.getString("testfile");
        if (testFile != "" && config.rootDir.isValid()) {
            // if specific file, clear directory
            config.rootDir = null;
            _singleTest = true;
            fi := FileInfo(testFile);
            if (!fi.exists()) {
                cerr `$testFile does not exist\n`;
                exit(1);
            }
            test := Test(fi, getDirConfig(Directory(fi.dirname())));
            _testList.push(test);
            config.showDiff = true;
            config.jobs = 1;
        }

        // banner
        //cout `screen\n`;

        // in the future, do a version check to make sure we have a good crack binary
        //checkBinary();
        
    }
    
    void showStats() {

        cout `total runtime: $(testSuiteStats.getTotalTime()) secs\n`;

        cnt := testSuiteStats.failList.count();
        if (cnt == 0) {
            cout `all tests passed\n`;
            return;
        }

        cout `-----------------------\n$cnt failing tests:\n`;
        for (f :in testSuiteStats.failList) {
            cout `$f\n`;
        }
        cout `-----------------------\n`;

    }

    void run() {
        
        if (config.rootDir)
            scanForTests(config.rootDir);

        if (!config.outDir.isValid()) {
            cerr `invalid output directory: $(config.outDir)\n`;
            return;
        }

        testSuiteStats.startStopwatch();
        runTests();
        testSuiteStats.stopStopwatch();

        if (!_singleTest)
            showStats();
        
    }

}

suite := TestSuite();
suite.run();

if (testSuiteStats.failList)
    exit(2);  # an exit code of 2 indicates that we failed due to a test 
              # failure
